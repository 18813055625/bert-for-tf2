{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Reviews with bert-for-tf2 on TPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpe/bert-for-tf2/blob/master/examples/tpu_movie_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgnJDqeiSPqc",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this colab notebook we will create a sentiment classifier on the IMDB Movie Reviews dataset.\n",
        "Our code will use the TensorFlow Keras API implementation of BERT from [kpe/bert-for-tf2](https://github.com/kpe/bert-for-tf2)\n",
        "and the pre-trained BERT weights from [google-research/bert](https://github.com/google-research/bert).\n",
        "We will also make use of the adapter-BERT architecture in order to fine-tune only a fraction of the weighs \n",
        "while keeping the original BERT weights frozen.\n",
        "\n",
        "The main challenge however would be to fine-tune the classifier on a colab TPU:\n",
        "\n",
        "Currently the combination of using a colab TPU with Keras could be quite tricky, so be prepared to do some tweaks:\n",
        " - **Google Storage Bucket** - TPUs have to load weights and training data from somewhere, and it currently looks like this has to be a google storage bucket. Therefore you'll need a write access to a bucket.\n",
        " - **GCP Authentication** - and because we have to use a Storage Bucket, we'd need to authorize our colab environment\n",
        " - **pre-trained BERT** - we'll also need to copy the pre-trained BERT weights to our storage bucket (because loading the checkpoint needs list permissions)\n",
        " - **TFRecord** - feeding data to a TPU seems to be best done using a tfrecords based dataset, so we'll convert our datasets into a tfrecord file(s) first\n",
        " - **TPU Training** - once we have the init checkpoint, we'll use `TPU Distribution Strategy` scope, to create the classification model instance.\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB_F9OQqKK_q",
        "colab_type": "text"
      },
      "source": [
        "# Storage Bucket Authentication\n",
        "\n",
        "You need to setup a storage bucket in GCP for storing and loading model weights and feeding data into the TPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXsSMfLdLeLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkkQli7WKdvJ",
        "colab_type": "code",
        "outputId": "554a9ace-a691-4ef8-d0e2-f74940d24a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "BUCKET = 'kpe' #@param {type:\"string\"}\n",
        "\n",
        "OUTPUT_DIR = 'movie_reviews_tpu'#@param {type:\"string\"}\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "OUTPUT_DIR = 'gs://{}/colab/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    # Doesn't matter if the directory didn't exist\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://kpe/colab/movie_reviews_tpu *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCpvgG0vwXAZ",
        "colab_type": "text"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFI2_B8ffipb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tqdm >> /dev/null\n",
        "\n",
        "#!pip install -q tensorflow==2.0.0-beta1 # TPU with Keras on TF 2.0 seems to have problems, so we don't use it yet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evlk1N78HIXM",
        "colab_type": "code",
        "outputId": "168d57c9-390e-4c22-b988-13be4f7b737f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqYo_14wJ_AY",
        "colab_type": "text"
      },
      "source": [
        "To enable the TPU - it seems to be neccessary to do this `tf.config.experimental` call in the beginning of the session:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAdrQqEccIva",
        "colab_type": "code",
        "outputId": "f49dcb08-5a4f-4ddf-deae-a786a4610e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "USE_TPU=True\n",
        "try:\n",
        "  # This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  tf.config.experimental_connect_to_host(TPU_WORKER)\n",
        "except Exception as ex:\n",
        "  print(ex)\n",
        "  USE_TPU=False\n",
        "\n",
        "print(\"        USE_TPU:\", USE_TPU)\n",
        "print(\"Eager Execution:\", tf.executing_eagerly())\n",
        "\n",
        "assert not tf.executing_eagerly(), \"Eager execution on TPUs have issues currently\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        USE_TPU: True\n",
            "Eager Execution: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp5wfXDx5SPH",
        "colab_type": "text"
      },
      "source": [
        "So lets also pip install the [bert-for-tf2](https://github.com/kpe/bert-for-tf2) python package,\n",
        "that will allow us to use the Keras API when coding our classifier model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-for-tf2 >> /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtI7cKWDbUVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bert import BertModelLayer\n",
        "from bert import FullTokenizer\n",
        "from bert import load_stock_weights, params_from_pretrained_ckpt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U4F7ZQY6sUP",
        "colab_type": "text"
      },
      "source": [
        "# The BERT Pre-Trained\n",
        "\n",
        "The original pre-trained BERT weights are available in a Google Storage Bucket at `gs://bert_models/`, but without list permission which are needed by the TensorFlow APIs used for loading the weights from a checkpoint, so we have to copy the pre-trained model to our own bucket:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw_F488eixTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ba0d41ca-3880-4f88-ce4e-67b893865f58"
      },
      "source": [
        "bert_ckpt_dir    = \"gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12\"\n",
        "bert_ckpt_file   = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")\n",
        "bert_model_name  = os.path.basename(os.path.dirname(bert_ckpt_file))\n",
        "\n",
        "bert_ckpt_files = [\"bert_config.json\",\n",
        "                   \"bert_model.ckpt.data-00000-of-00001\",\n",
        "                   \"bert_model.ckpt.index\",\n",
        "                   \"bert_model.ckpt.meta\",\n",
        "                   \"vocab.txt\"]\n",
        "\n",
        "gs_bert_ckpt_dir = os.path.join(OUTPUT_DIR, \"bert_models\", bert_model_name)\n",
        "if not tf.io.gfile.exists(gs_bert_ckpt_dir):\n",
        "    cmd = \"gsutil -m cp {} {}\".format(\n",
        "        \" \".join(map(partial(os.path.join, bert_ckpt_dir), bert_ckpt_files)),\n",
        "        gs_bert_ckpt_dir)\n",
        "    !$cmd\n",
        "\n",
        "!gsutil ls $gs_bert_ckpt_dir"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/bert_config.json [Content-Type=application/json]...\n",
            "/ [0 files][    0.0 B/  313.0 B]                                                \rCopying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/420.0 MiB]                                                \rCopying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/bert_model.ckpt.index [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/420.0 MiB]                                                \rCopying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/bert_model.ckpt.meta [Content-Type=application/octet-stream]...\n",
            "Copying gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12/vocab.txt [Content-Type=text/plain]...\n",
            "- [5/5 files][421.1 MiB/421.1 MiB] 100% Done                                    \n",
            "Operation completed over 5 objects/421.1 MiB.                                    \n",
            "gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQiPKscKPpmT",
        "colab_type": "code",
        "outputId": "2fd83c90-3a5a-4290-8fbe-c4522308c8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bert_ckpt_dir    = gs_bert_ckpt_dir\n",
        "bert_ckpt_file   = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")\n",
        "\n",
        "print(\"Using BERT checkpoint from:\", bert_ckpt_dir)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using BERT checkpoint from: gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmFYvkylMwXn",
        "colab_type": "text"
      },
      "source": [
        "# The IMDB Movie Review Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_w8SRqN0fr",
        "colab_type": "text"
      },
      "source": [
        "First, let's download the dataset, hosted by Stanford. \n",
        "The code below, which downloads, extracts, and imports the IMDB Large Movie Review Dataset \n",
        "is borrowed from [this Tensorflow tutorial](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fom_ff20gyy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in tqdm(os.listdir(directory), desc=os.path.basename(directory)):\n",
        "    with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtwqPpZO-FOk",
        "colab_type": "text"
      },
      "source": [
        "Now we'll make a utility class `MovieReviewDatasetBuilder` for pre-processing (i.e. tokenizing) the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfuoW_K207HV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MovieReviewDatasetBuilder:\n",
        "  DATA_COLUMN = \"sentence\"\n",
        "  LABEL_COLUMN = \"polarity\"\n",
        "\n",
        "  def __init__(self, tokenizer: FullTokenizer):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_seq_len = 0\n",
        "    \n",
        "    (self.cls_id, \n",
        "     self.sep_id,\n",
        "     self.pad_id) = self.tokenizer.convert_tokens_to_ids([\"[CLS]\", \n",
        "                                                          \"[SEP]\", \n",
        "                                                          \"[PAD]\"])\n",
        "    \n",
        "    train, test = download_and_load_datasets()\n",
        "    \n",
        "    def sort_df(df):\n",
        "      sorted_index = df[self.DATA_COLUMN].str.len().sort_values().index\n",
        "      return df.reindex(sorted_index)\n",
        "    \n",
        "    train, test = map(sort_df, [train, test])\n",
        "    \n",
        "    ((self.train_ids, self.train_y),\n",
        "     (self.test_ids, self.test_y)) = map(self._tokenize_data, [train, test])        \n",
        "    \n",
        "    print(\"max_seq_len\", self.max_seq_len)\n",
        "    \n",
        "    \n",
        "  def _tokenize_data(self, df):\n",
        "    x, y = [], []\n",
        "    with tqdm(total=df.shape[0], unit_scale=True) as pbar:\n",
        "      for ndx, row in df.iterrows():\n",
        "        text, label = row[self.DATA_COLUMN], row[self.LABEL_COLUMN]\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
        "        x.append(token_ids)\n",
        "        y.append(int(label))\n",
        "        pbar.update()\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYwlvtPK08Ec",
        "colab_type": "text"
      },
      "source": [
        "# The TFRecords Conversion\n",
        "\n",
        "We should also convert the raw dataset into TFRecord files, which are easier to feed into a TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9rORqVi5sii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MovieReviewDS:\n",
        "  \n",
        "  @staticmethod\n",
        "  def serialize_example(token_ids, label):\n",
        "    feature = {\n",
        "        \"token_ids\": tf.train.Feature(int64_list=tf.train.Int64List(value=token_ids)),\n",
        "        \"label\":     tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
        "    }\n",
        "    proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    return proto.SerializeToString()\n",
        "\n",
        "  @staticmethod\n",
        "  def write_tf_record(file_name, x, y):\n",
        "    with tf.python_io.TFRecordWriter(file_name) as writer:\n",
        "      with tqdm(total=len(x), unit_scale=True, desc=os.path.basename(file_name)) as pbar:\n",
        "        for token_ids, label in zip(x, y):\n",
        "          example = MovieReviewDS.serialize_example(token_ids, label)\n",
        "          writer.write(example)\n",
        "          pbar.update()\n",
        "    \n",
        "  @staticmethod\n",
        "  def create_pad_example_fn(pad_len, padding=0):\n",
        "    def pad_example(x, label):\n",
        "      x = x[-pad_len:]\n",
        "      # x = tf.concat([x, padding*tf.ones(pad_len - tf.shape(x)[-1], dtype=x.dtype)], axis=-1)\n",
        "      x = tf.pad(x, [[0, pad_len - tf.shape(x)[-1]]], constant_values=padding)\n",
        "      return x, label\n",
        "    return pad_example\n",
        "    \n",
        "  @staticmethod\n",
        "  def tfrecord_to_dataset(filenames):\n",
        "    ds = tf.data.TFRecordDataset(filenames)\n",
        "    feature_description = {\n",
        "        \"token_ids\":  tf.io.VarLenFeature(tf.int64),\n",
        "        \"label\":      tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
        "    }\n",
        "    \n",
        "    def parse_proto(proto):\n",
        "      example = tf.io.parse_single_example(proto, feature_description)\n",
        "      token_ids, label = example[\"token_ids\"], example[\"label\"]\n",
        "      token_ids = tf.sparse_tensor_to_dense(token_ids)\n",
        "      return token_ids, label\n",
        "    \n",
        "    return ds.map(parse_proto)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igZnhhTA3hmH",
        "colab_type": "text"
      },
      "source": [
        "We would also store the `tfrecords` in out bucket:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R454eTyqIKnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tfrecord_file = os.path.join(OUTPUT_DIR, \"data\", \"train.tfrecord\")\n",
        "test_tfrecord_file  = os.path.join(OUTPUT_DIR, \"data\", \"test.tfrecord\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkSCcZTj-c5j",
        "colab_type": "text"
      },
      "source": [
        "Converting all the data to `tfrecord` files takes few minutes, so we'll try not doing it twice: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82zTEjIf57k_",
        "colab_type": "code",
        "outputId": "7dc770bb-ddbb-4388-87e1-5518a4e22944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "\n",
        "if not all([tf.io.gfile.exists(train_tfrecord_file),\n",
        "            tf.io.gfile.exists(test_tfrecord_file)]):\n",
        "  print(\"Preparing the [train, test].tfrecord files...\")\n",
        "  \n",
        "  tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))\n",
        "  data = MovieReviewDatasetBuilder(tokenizer)\n",
        "  \n",
        "  MovieReviewDS.write_tf_record(train_tfrecord_file, data.train_ids, data.train_y)\n",
        "  MovieReviewDS.write_tf_record(test_tfrecord_file, data.test_ids, data.test_y)\n",
        "else:\n",
        "  data = None\n",
        "\n",
        "!gsutil ls -la $train_tfrecord_file \n",
        "!gsutil ls -la $test_tfrecord_file"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing the [train, test].tfrecord files...\n",
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "pos: 100%|██████████| 12500/12500 [00:01<00:00, 6774.07it/s]\n",
            "neg: 100%|██████████| 12500/12500 [00:01<00:00, 6681.91it/s]\n",
            "pos: 100%|██████████| 12500/12500 [00:01<00:00, 6919.09it/s]\n",
            "neg: 100%|██████████| 12500/12500 [00:01<00:00, 6867.15it/s]\n",
            "100%|██████████| 25.0k/25.0k [02:31<00:00, 166it/s] \n",
            "100%|██████████| 25.0k/25.0k [02:26<00:00, 171it/s] \n",
            "train.tfrecord:   5%|▍         | 1.16k/25.0k [00:00<00:02, 11.5kit/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_seq_len 3155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train.tfrecord: 100%|██████████| 25.0k/25.0k [00:03<00:00, 6.93kit/s]\n",
            "test.tfrecord: 100%|██████████| 25.0k/25.0k [00:03<00:00, 7.14kit/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  17370602  2019-08-06T10:55:25Z  gs://kpe/colab/movie_reviews_tpu/data/train.tfrecord#1565088925037707  metageneration=1\n",
            "TOTAL: 1 objects, 17370602 bytes (16.57 MiB)\n",
            "  17005906  2019-08-06T10:55:29Z  gs://kpe/colab/movie_reviews_tpu/data/test.tfrecord#1565088929072282  metageneration=1\n",
            "TOTAL: 1 objects, 17005906 bytes (16.22 MiB)\n",
            "CPU times: user 5min 26s, sys: 12.7 s, total: 5min 39s\n",
            "Wall time: 5min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjlcx1E9-2ns",
        "colab_type": "text"
      },
      "source": [
        "Because BERT can handle up to 512 tokens, and because BERT computational and memory requirements scale quadratically with the input sequence length, we will have to trim the sequences to a shorter size, but let's first check the sequence length distribution, and how many examples would be affected, if we trimm all sequences to 512 tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqnvWHuY9cZ0",
        "colab_type": "code",
        "outputId": "2d4e9d17-a627-4a3f-912a-416fbfcd8df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "if data:\n",
        "  train_df = pd.DataFrame(map(len, data.train_ids.tolist()))\n",
        "  test_df  = pd.DataFrame(map(len, data.test_ids.tolist()))\n",
        "\n",
        "  train_df.hist(bins=100), test_df.hist(bins=100);\n",
        "\n",
        "\n",
        "  def show_drop_counts(max_seq_len = 512):\n",
        "    drop_count_train, drop_count_test = map(lambda df: df[df[0] > (max_seq_len-2)].shape[0], [train_df, test_df])\n",
        "    print(\"train drop count: {} of {} - {:5.2f}%\".format(drop_count_train, len(train_df), 100*drop_count_train/len(train_df)))\n",
        "    print(\" test drop count: {} of {} - {:5.2f}%\".format(drop_count_test, len(test_df), 100*drop_count_test/len(test_df)))\n",
        "  \n",
        "  show_drop_counts(512)\n",
        "  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train drop count: 3701 of 25000 - 14.80%\n",
            " test drop count: 3513 of 25000 - 14.05%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k1T2Vh9_k3k",
        "colab_type": "text"
      },
      "source": [
        "Reading the preprocessed dataset from a tfrecord file could be done like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7pglY3X7rYa",
        "colab_type": "code",
        "outputId": "658787dd-019a-409c-e8a9-2feb5a1e8f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "max_seq_len = 12\n",
        "train_ds = MovieReviewDS.tfrecord_to_dataset([train_tfrecord_file])\n",
        "train_ds = train_ds.map(MovieReviewDS.create_pad_example_fn(pad_len=max_seq_len, \n",
        "                                                            padding=0))\n",
        "\n",
        "test_ds = MovieReviewDS.tfrecord_to_dataset([test_tfrecord_file])\n",
        "test_ds = test_ds.map(MovieReviewDS.create_pad_example_fn(pad_len=max_seq_len, \n",
        "                                                          padding=0))\n",
        "\n",
        "train_ds_size, test_ds_size = 0, 0\n",
        "if tf.executing_eagerly():\n",
        "  for token_ids, label in train_ds.take(5):\n",
        "    print(token_ids.shape, label.numpy(), token_ids.numpy())\n",
        "  def get_ds_size(ds):\n",
        "    return sum([1 for _ in ds])\n",
        "  train_ds_size, test_ds_size = map(get_ds_size, [train_ds, test_ds])\n",
        "else:\n",
        "  def get_ds_size(ds):\n",
        "    count = 0\n",
        "    with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      it = ds.batch(128).make_one_shot_iterator()\n",
        "      tok_ids,labels = it.get_next()\n",
        "  \n",
        "      try:\n",
        "        while True:\n",
        "          res = sess.run(labels)\n",
        "          count += res.shape[0]\n",
        "      except Exception as ex:\n",
        "        pass\n",
        "    return count\n",
        "  train_ds_size, test_ds_size = map(get_ds_size, [train_ds, test_ds])\n",
        "  \n",
        "print(\"train size:\", train_ds_size)\n",
        "print(\" test size:\", test_ds_size)\n",
        "\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0806 10:55:36.281256 140206113781632 deprecation.py:323] From <ipython-input-17-a645a183e8d5>:22: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train size: 25000\n",
            " test size: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olroXq3_WiQt",
        "colab_type": "text"
      },
      "source": [
        "# The Model (finally)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfRnHSz3iSXz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Lets define some helpers for freezing some selected BERT layers, which is need for [adapter-BERT](https://arxiv.org/abs/1902.00751)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMOGwFui4it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def flatten_layers(root_layer):\n",
        "    if isinstance(root_layer, keras.layers.Layer):\n",
        "        yield root_layer\n",
        "    for layer in root_layer._layers:\n",
        "        for sub_layer in flatten_layers(layer):\n",
        "            yield sub_layer\n",
        "\n",
        "\n",
        "def freeze_bert_layers(l_bert):\n",
        "    \"\"\"\n",
        "    Freezes all but LayerNorm and adapter layers - see arXiv:1902.00751.\n",
        "    \"\"\"\n",
        "    for layer in flatten_layers(l_bert):\n",
        "        if layer.name in [\"LayerNorm\", \"adapter-down\", \"adapter-up\"]:\n",
        "            layer.trainable = True\n",
        "        elif len(layer._layers) == 0:\n",
        "            layer.trainable = False\n",
        "        l_bert.embeddings_layer.trainable = False\n",
        "\n",
        "\n",
        "def create_learning_rate_scheduler(max_learn_rate=5e-5,\n",
        "                                   end_learn_rate=1e-7,\n",
        "                                   warmup_epoch_count=10,\n",
        "                                   total_epoch_count=90):\n",
        "\n",
        "    def lr_scheduler(epoch):\n",
        "        if epoch < warmup_epoch_count:\n",
        "            res = (max_learn_rate/warmup_epoch_count) * (epoch + 1)\n",
        "        else:\n",
        "            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(epoch-warmup_epoch_count+1)/(total_epoch_count-warmup_epoch_count+1))\n",
        "        return float(res)\n",
        "    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "\n",
        "    return learning_rate_scheduler\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccp5trMwRtmr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Now let's create a classification model using [adapter-BERT](https//arxiv.org/abs/1902.00751), which is a clever way \n",
        "of reducing the trainable parameter count, by freezing the original BERT weights, \n",
        "and adapting the internal activations with two FFN bottlenecks (i.e. `adapter_size` bellow) in every BERT layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o2a5ZIvRcJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(max_seq_len, \n",
        "                 adapter_size=64,\n",
        "                 batch_size=None,\n",
        "                 init_ckpt_file=None,\n",
        "                 init_bert_ckpt_file=bert_ckpt_file,\n",
        "                ):\n",
        "  \"\"\"Creates a classification model.\n",
        "  :param adapter_size: adapter bottleneck size - arXiv:1902.00751\n",
        "  \"\"\"\n",
        "\n",
        "  bert_params = params_from_pretrained_ckpt(os.path.dirname(init_bert_ckpt_file))\n",
        "  \n",
        "  # create the bert layer\n",
        "  bert_params.adapter_size = adapter_size\n",
        "  l_bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.InputLayer(input_shape=(max_seq_len,), batch_size=batch_size,\n",
        "                              dtype=\"int32\", name=\"input_ids\"),\n",
        "      l_bert,\n",
        "      keras.layers.Lambda(lambda seq: seq[:, 0, :]),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(units=bert_params.hidden_size, activation=\"relu\"),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(units=2, activation=\"softmax\")\n",
        "  ])\n",
        "  \n",
        "  # freeze the weights if adapter-BERT is used\n",
        "  #    we need to freeze the layers\n",
        "  #    before we do build/compile \n",
        "  #    otherwise keras counts the params twice in its Model Summary Total\n",
        "  if adapter_size is not None:\n",
        "    freeze_bert_layers(l_bert)\n",
        "  \n",
        "  model.build(input_shape=(batch_size, max_seq_len))\n",
        "  \n",
        "  model.compile(optimizer=keras.optimizers.Adam(),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\n",
        "\n",
        "  # load the pre-trained model weights (once the input_shape is known)\n",
        "  if init_ckpt_file:\n",
        "    print(\"Loading model weights from:\", init_ckpt_file)\n",
        "    model.load_weights(init_ckpt_file)\n",
        "  elif init_bert_ckpt_file:\n",
        "    print(\"Loading pre-trained BERT layer from:\", init_bert_ckpt_file)\n",
        "    load_stock_weights(l_bert, init_bert_ckpt_file)\n",
        "\n",
        "  \n",
        "  model.summary()\n",
        "        \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMEsolbw4Xo-",
        "colab_type": "text"
      },
      "source": [
        "Bigger `max_seq_len` in a transformer model slows things quite a bit, \n",
        "but will select the maximum for BERT which is 512:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cyROAuVljmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adapter_size = 64\n",
        "max_seq_len  = 512\n",
        "batch_size   = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTy5V6Js5FTo",
        "colab_type": "text"
      },
      "source": [
        "So we are now finally ready to create our model. To make it run on a TPU, we need to wrap the \n",
        "creation into a `TPUStrategy` scope:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAXDrezB0ijW",
        "colab_type": "code",
        "outputId": "5b4a82bc-665c-4355-ec77-089f98deaf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "assert not tf.executing_eagerly()\n",
        "\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "  model = create_model(max_seq_len,\n",
        "                       adapter_size, \n",
        "                       batch_size=batch_size,\n",
        "                       init_bert_ckpt_file=bert_ckpt_file)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0806 10:55:49.429897 140206113781632 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0806 10:55:49.569336 140206113781632 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0806 10:56:10.608681 140206113781632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/bert/loader.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pre-trained BERT layer from: gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "loader: No value for:[bert/encoder/layer_0/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_0/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_0/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_0/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_0/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_0/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_0/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_0/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_0/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_0/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_0/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_0/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_0/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_0/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_0/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_0/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_1/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_1/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_1/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_1/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_1/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_1/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_1/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_1/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_1/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_1/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_1/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_1/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_1/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_1/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_1/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_1/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_2/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_2/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_2/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_2/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_2/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_2/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_2/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_2/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_2/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_2/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_2/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_2/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_2/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_2/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_2/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_2/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_3/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_3/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_3/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_3/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_3/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_3/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_3/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_3/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_3/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_3/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_3/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_3/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_3/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_3/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_3/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_3/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_4/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_4/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_4/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_4/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_4/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_4/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_4/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_4/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_4/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_4/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_4/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_4/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_4/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_4/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_4/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_4/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_5/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_5/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_5/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_5/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_5/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_5/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_5/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_5/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_5/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_5/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_5/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_5/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_5/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_5/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_5/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_5/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_6/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_6/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_6/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_6/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_6/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_6/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_6/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_6/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_6/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_6/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_6/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_6/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_6/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_6/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_6/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_6/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_7/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_7/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_7/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_7/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_7/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_7/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_7/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_7/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_7/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_7/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_7/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_7/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_7/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_7/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_7/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_7/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_8/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_8/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_8/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_8/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_8/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_8/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_8/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_8/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_8/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_8/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_8/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_8/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_8/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_8/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_8/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_8/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_9/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_9/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_9/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_9/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_9/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_9/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_9/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_9/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_9/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_9/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_9/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_9/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_9/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_9/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_9/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_9/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_10/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_10/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_10/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_10/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_10/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_10/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_10/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_10/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_10/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_10/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_10/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_10/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_10/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_10/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_10/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_10/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_11/attention/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_11/attention/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_11/attention/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_11/attention/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_11/attention/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_11/attention/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_11/attention/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_11/attention/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_11/output/adapter-down/kernel:0], i.e.:[bert/encoder/layer_11/output/adapter-down/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_11/output/adapter-down/bias:0], i.e.:[bert/encoder/layer_11/output/adapter-down/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_11/output/adapter-up/kernel:0], i.e.:[bert/encoder/layer_11/output/adapter-up/kernel] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "loader: No value for:[bert/encoder/layer_11/output/adapter-up/bias:0], i.e.:[bert/encoder/layer_11/output/adapter-up/bias] in:[gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt]\n",
            "Done loading 196 BERT weights from: gs://kpe/colab/movie_reviews_tpu/bert_models/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7f840cec59e8> (prefix:bert). Count of weights not found in the checkpoint was: 96\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (BertModelLayer)        (16, 512, 768)            111269376 \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (16, 768)                 0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (16, 768)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (16, 768)                 590592    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (16, 768)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (16, 2)                   1538      \n",
            "=================================================================\n",
            "Total params: 111,861,506\n",
            "Trainable params: 3,008,258\n",
            "Non-trainable params: 108,853,248\n",
            "_________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (BertModelLayer)        (16, 512, 768)            111269376 \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (16, 768)                 0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (16, 768)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (16, 768)                 590592    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (16, 768)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (16, 2)                   1538      \n",
            "=================================================================\n",
            "Total params: 111,861,506\n",
            "Trainable params: 3,008,258\n",
            "Non-trainable params: 108,853,248\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8yFOEiIkswR",
        "colab_type": "code",
        "outputId": "a8f9510d-fa24-4686-81d4-d1145f74d227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "\n",
        "ds = MovieReviewDS.tfrecord_to_dataset([train_tfrecord_file])\n",
        "ds = ds.map(MovieReviewDS.create_pad_example_fn(pad_len=max_seq_len, \n",
        "                                                padding=0))\n",
        "def set_example_shape(token_ids, label):\n",
        "  return tf.reshape(token_ids, (max_seq_len,)), tf.reshape(label, ())\n",
        "\n",
        "\n",
        "ds = ds.map(set_example_shape)\n",
        "ds = ds.cache()\n",
        "ds = ds.shuffle(buffer_size=2500, seed=4711, reshuffle_each_iteration=True)\n",
        "\n",
        "#train_size  = int((25000*0.9//128)*128)\n",
        "#train_ds = ds.take(train_size)\n",
        "#valid_ds = ds.batch\n",
        "#ds = train_ds.cache()\n",
        "#ds = ds.shuffle(buffer_size=batch_size*32, reshuffle_each_iteration=True)\n",
        "\n",
        "ds = ds.repeat()\n",
        "ds = ds.batch(batch_size, drop_remainder=True)\n",
        "train_ds = ds"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0806 10:57:13.497962 140206113781632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jFBFOOK46iF",
        "colab_type": "text"
      },
      "source": [
        "Once the model is trained, we'll store it in our bucket:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrQ6Zh2PigjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trained_ckpt_file = os.path.join(OUTPUT_DIR, 'checkpoints','trained','movie_reviews.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chq22MBJ5DEw",
        "colab_type": "text"
      },
      "source": [
        "and now lets proceed with the actual training on a TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuLOkwonF-9S",
        "colab_type": "code",
        "outputId": "d78d5971-325f-49bf-cb55-0df4ab4480d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#%%time\n",
        "\n",
        "if tf.io.gfile.exists(trained_ckpt_file):\n",
        "  model.load_weights(trained_ckpt_file)\n",
        "else:\n",
        "  log_dir = os.path.join(OUTPUT_DIR, \"log\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "  tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "  total_epoch_count = 30\n",
        "\n",
        "  model.fit(train_ds,\n",
        "            shuffle=True,\n",
        "            epochs=total_epoch_count,\n",
        "            steps_per_epoch=25000//batch_size,\n",
        "            callbacks=[create_learning_rate_scheduler(max_learn_rate=5e-5,\n",
        "                                                      end_learn_rate=5e-7,\n",
        "                                                      warmup_epoch_count=10,\n",
        "                                                      total_epoch_count=total_epoch_count),\n",
        "                       keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                       tensorboard_callback])\n",
        "  model.save_weights(trained_ckpt_file, overwrite=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0806 10:58:27.599105 140206113781632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 5e-06.\n",
            "Epoch 1/30\n",
            "  2/195 [..............................] - ETA: 56:55 - loss: 5.6345 - acc: 0.5312  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 10:59:02.997966 140206113781632 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (1.092324). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "194/195 [============================>.] - ETA: 0s - loss: 5.6958 - acc: 0.5033"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:00:30.795150 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 124s 638ms/step - loss: 5.6965 - acc: 0.5031\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 2/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 5.3282 - acc: 0.5924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:02:00.764044 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 458ms/step - loss: 5.3248 - acc: 0.5931\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 1.5000000000000002e-05.\n",
            "Epoch 3/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.8127 - acc: 0.8326"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:03:29.972693 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.8112 - acc: 0.8328\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 2e-05.\n",
            "Epoch 4/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.5047 - acc: 0.8692"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:04:59.644582 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 457ms/step - loss: 3.5068 - acc: 0.8689\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 2.5e-05.\n",
            "Epoch 5/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.4054 - acc: 0.8827"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:06:28.900254 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.4060 - acc: 0.8826\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 3.0000000000000004e-05.\n",
            "Epoch 6/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.3660 - acc: 0.8882"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:07:58.940879 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 457ms/step - loss: 3.3656 - acc: 0.8883\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 3.5000000000000004e-05.\n",
            "Epoch 7/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.3091 - acc: 0.8958"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:09:28.114408 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 460ms/step - loss: 3.3111 - acc: 0.8956\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 4e-05.\n",
            "Epoch 8/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.2701 - acc: 0.9003"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:10:57.898444 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 457ms/step - loss: 3.2708 - acc: 0.9002\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 4.5e-05.\n",
            "Epoch 9/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.2744 - acc: 0.9003"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:12:27.236196 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 462ms/step - loss: 3.2756 - acc: 0.9002\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 5e-05.\n",
            "Epoch 10/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.2075 - acc: 0.9091"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:13:57.290508 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 458ms/step - loss: 3.2089 - acc: 0.9089\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 4.015428610695757e-05.\n",
            "Epoch 11/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.1997 - acc: 0.9100"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:15:26.385341 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.2010 - acc: 0.9099\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 3.2247333855188115e-05.\n",
            "Epoch 12/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.1605 - acc: 0.9144"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:16:56.096100 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 457ms/step - loss: 3.1616 - acc: 0.9143\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 2.5897373396156056e-05.\n",
            "Epoch 13/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.1550 - acc: 0.9159"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:18:25.468137 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.1560 - acc: 0.9158\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 2.0797810815359234e-05.\n",
            "Epoch 14/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.1238 - acc: 0.9203"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:19:55.265007 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 458ms/step - loss: 3.1265 - acc: 0.9200\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 1.670242491756622e-05.\n",
            "Epoch 15/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.1321 - acc: 0.9190"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:21:24.600560 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.1340 - acc: 0.9188\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 1.341347897639863e-05.\n",
            "Epoch 16/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.1166 - acc: 0.9205"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:22:54.508530 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 458ms/step - loss: 3.1172 - acc: 0.9204\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 1.0772173450159417e-05.\n",
            "Epoch 17/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.1134 - acc: 0.9211"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:24:23.681378 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 460ms/step - loss: 3.1137 - acc: 0.9210\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 8.65097869422947e-06.\n",
            "Epoch 18/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0902 - acc: 0.9247"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:25:53.453275 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 458ms/step - loss: 3.0903 - acc: 0.9247\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 6.947477471865686e-06.\n",
            "Epoch 19/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0948 - acc: 0.9243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:27:22.794784 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.0954 - acc: 0.9242\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 5.5794199625387414e-06.\n",
            "Epoch 20/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0900 - acc: 0.9251"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:28:52.768064 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 457ms/step - loss: 3.0904 - acc: 0.9250\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 4.480752509733022e-06.\n",
            "Epoch 21/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0864 - acc: 0.9251"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:30:22.033513 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.0872 - acc: 0.9251\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 3.59842836500576e-06.\n",
            "Epoch 22/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0880 - acc: 0.9251"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:31:51.857927 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 458ms/step - loss: 3.0901 - acc: 0.9249\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 2.8898464420766556e-06.\n",
            "Epoch 23/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0886 - acc: 0.9246"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:33:20.991935 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.0900 - acc: 0.9244\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 2.320794416806389e-06.\n",
            "Epoch 24/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0894 - acc: 0.9242"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:34:50.818702 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 457ms/step - loss: 3.0897 - acc: 0.9242\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 1.8637968601574692e-06.\n",
            "Epoch 25/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0820 - acc: 0.9263"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:36:19.894803 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 460ms/step - loss: 3.0821 - acc: 0.9262\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 1.4967886473602442e-06.\n",
            "Epoch 26/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0805 - acc: 0.9263"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:37:49.775589 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 458ms/step - loss: 3.0811 - acc: 0.9262\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 1.202049591754986e-06.\n",
            "Epoch 27/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0807 - acc: 0.9259"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:39:18.902029 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.0807 - acc: 0.9258\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 9.653488644416245e-07.\n",
            "Epoch 28/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0867 - acc: 0.9246"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:40:48.958532 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 457ms/step - loss: 3.0874 - acc: 0.9246\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 7.752578899163118e-07.\n",
            "Epoch 29/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0762 - acc: 0.9265"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:42:18.208779 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 90s 461ms/step - loss: 3.0769 - acc: 0.9264\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 6.225985423675161e-07.\n",
            "Epoch 30/30\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.0866 - acc: 0.9256"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0806 11:43:48.085472 140206113781632 callbacks.py:1259] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r195/195 [==============================] - 89s 457ms/step - loss: 3.0861 - acc: 0.9257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_Bbk6c_hPud",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "To evaluate, we'd prepare a dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBkGzomBiWjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def to_model_ds(tfrecord_file, batch_size=batch_size, drop_remainder=True):\n",
        "  ds = MovieReviewDS.tfrecord_to_dataset([tfrecord_file])\n",
        "  ds = ds.map(MovieReviewDS.create_pad_example_fn(pad_len=max_seq_len, \n",
        "                                                  padding=0))\n",
        "  def set_example_shape(token_ids, label):\n",
        "    return tf.reshape(token_ids, (max_seq_len,)), tf.reshape(label, ())\n",
        "\n",
        "  ds = ds.map(set_example_shape)\n",
        "  ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loylsQ6V6FmA",
        "colab_type": "text"
      },
      "source": [
        "and call evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VUk8f8KYzeI",
        "colab_type": "code",
        "outputId": "b065203b-9bdd-4a71-f9dc-daf9250f5f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "\n",
        "_, train_acc = model.evaluate(to_model_ds(train_tfrecord_file), steps=25000//batch_size)\n",
        "_, test_acc = model.evaluate(to_model_ds(test_tfrecord_file), steps=25000//batch_size)\n",
        "\n",
        "print(\"train acc\", train_acc)\n",
        "print(\" test acc\", test_acc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195/195 [==============================] - 74s 380ms/step\n",
            "195/195 [==============================] - 74s 380ms/step\n",
            "195/195 [==============================] - 80s 411ms/step\n",
            "195/195 [==============================] - 80s 411ms/step\n",
            "train acc 0.9323317\n",
            " test acc 0.9233174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9A53X8V5V8G",
        "colab_type": "text"
      },
      "source": [
        "We could also create a new model, load the trained checkpoint and evaluate. \n",
        "Beware however that this would take ages on a CPU, so you might prefer running the lines below in a new GPU session:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSqMu64oHzqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b4d092c-6c3e-4e2e-f0f8-408f8bcf750f"
      },
      "source": [
        "trained_ckpt_file = os.path.join(OUTPUT_DIR, 'checkpoints','trained','movie_reviews.ckpt')\n",
        "\n",
        "model = create_model(max_seq_len, \n",
        "                     adapter_size=adapter_size,\n",
        "                     init_ckpt_file=trained_ckpt_file)\n",
        "\n",
        "_, train_acc = model.evaluate(to_model_ds(train_tfrecord_file, drop_remainder=False))\n",
        "_, test_acc = model.evaluate(to_model_ds(test_tfrecord_file, drop_remainder=False))\n",
        "\n",
        "print(\"train acc\", train_acc)\n",
        "print(\" test acc\", test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model weights from: gs://kpe/colab/movie_reviews_tpu/checkpoints/trained/movie_reviews.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt-Rv-2hsW1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}